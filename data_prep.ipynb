{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baac60a-207b-428d-86db-deda76aede4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7552 images found out of 7552 total.\n"
     ]
    }
   ],
   "source": [
    "import os #\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "retina_df = pd.read_csv(\"/home/studio-lab-user/sage/segregated_images/labels.csv\")\n",
    "\n",
    "# Define the base image directories\n",
    "base_image_dirs = [\n",
    "    '/home/studio-lab-user/sage/segregated_images/0',\n",
    "    '/home/studio-lab-user/sage/segregated_images/1',\n",
    "    '/home/studio-lab-user/sage/segregated_images/2',\n",
    "    '/home/studio-lab-user/sage/segregated_images/3',\n",
    "    '/home/studio-lab-user/sage/segregated_images/4',\n",
    "]\n",
    "\n",
    "# Create the full file path for each image and check if the image files exist (.jpeg, .jpg, .png)\n",
    "def find_image_path(image_name):\n",
    "    for base_dir in base_image_dirs:\n",
    "        for ext in ['.jpeg', '.jpg', '.png']:\n",
    "            path = os.path.join(base_dir, f\"{image_name}{ext}\")\n",
    "            if os.path.exists(path):\n",
    "                return path\n",
    "    return None\n",
    "\n",
    "# Apply the function to each image\n",
    "retina_df['path'] = retina_df['name'].map(find_image_path)\n",
    "retina_df['exists'] = retina_df['path'].notnull()\n",
    "\n",
    "# Print the number of images found\n",
    "print(f\"{retina_df['exists'].sum()} images found out of {retina_df.shape[0]} total.\")\n",
    "\n",
    "# Filter the DataFrame to only include rows where the image files exist\n",
    "retina_df = retina_df[retina_df['exists']]\n",
    "retina_df = retina_df[['path','label']]\n",
    "# Save the updated DataFrame\n",
    "retina_df.to_csv(r\"/home/studio-lab-user/sage/segregated_images/labels_pth.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83751126-e8b5-4379-90f4-d0427e03e28b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original counts per level:\n",
      "label\n",
      "0    4036\n",
      "1    1323\n",
      "3    1036\n",
      "2     732\n",
      "4     425\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Removed counts per level:\n",
      "{0: 25, 1: 25, 2: 25, 3: 25, 4: 25}\n",
      "\n",
      "New counts per level:\n",
      "label\n",
      "0    4011\n",
      "1    1298\n",
      "3    1011\n",
      "2     707\n",
      "4     400\n",
      "Name: count, dtype: int64\n",
      "No discrepancies detected.\n",
      "Removed records saved as '/home/studio-lab-user/sage/segregated_images/labels_test.csv'.\n",
      "Remaining records saved as '/home/studio-lab-user/sage/segregated_images/labels_train.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def remove_and_verify_records(csv_file, num_to_remove, removed_csv_file, remaining_csv_file):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Dictionary to store record counts\n",
    "    original_counts = df['label'].value_counts()\n",
    "    removed_counts = {}\n",
    "\n",
    "    # Create DataFrames to store the removed and remaining records\n",
    "    removed_df = pd.DataFrame()\n",
    "    remaining_df = pd.DataFrame()\n",
    "\n",
    "    # Group by 'level'\n",
    "    grouped = df.groupby('label')\n",
    "\n",
    "    # Iterate over each group\n",
    "    for level, group in grouped:\n",
    "        if len(group) > num_to_remove:\n",
    "            # Randomly sample num_to_remove records to remove\n",
    "            to_remove = group.sample(n=num_to_remove, random_state=42)\n",
    "            removed_counts[level] = to_remove.shape[0]\n",
    "            # Append the removed records to the removed DataFrame\n",
    "            removed_df = pd.concat([removed_df, to_remove])\n",
    "            # Drop the sampled records from the group\n",
    "            group = group.drop(to_remove.index)\n",
    "        else:\n",
    "            removed_counts[level] = 0\n",
    "\n",
    "        # Append the remaining records to the remaining DataFrame\n",
    "        remaining_df = pd.concat([remaining_df, group])\n",
    "\n",
    "    # Save the removed records to a new CSV file\n",
    "    removed_df.to_csv(removed_csv_file, index=False)\n",
    "    # Save the remaining records to a new CSV file\n",
    "    remaining_df.to_csv(remaining_csv_file, index=False)\n",
    "\n",
    "    # Calculate new counts after removal\n",
    "    new_counts = remaining_df['label'].value_counts()\n",
    "\n",
    "    # Print record counts for verification\n",
    "    print(\"Original counts per level:\")\n",
    "    print(original_counts)\n",
    "    print(\"\\nRemoved counts per level:\")\n",
    "    print(removed_counts)\n",
    "    print(\"\\nNew counts per level:\")\n",
    "    print(new_counts)\n",
    "\n",
    "    # Verify the number of records removed\n",
    "    discrepancies = []\n",
    "    for level in original_counts.index:\n",
    "        expected_count = original_counts[level] - removed_counts.get(level, 0)\n",
    "        actual_count = new_counts.get(level, 0)\n",
    "        if expected_count != actual_count:\n",
    "            discrepancies.append((level, expected_count, actual_count))\n",
    "\n",
    "    if discrepancies:\n",
    "        for level, expected, actual in discrepancies:\n",
    "            print(f\"Discrepancy detected for level {level}: Expected {expected}, Found {actual}\")\n",
    "    else:\n",
    "        print(\"No discrepancies detected.\")\n",
    "\n",
    "    print(f\"Removed records saved as '{removed_csv_file}'.\")\n",
    "    print(f\"Remaining records saved as '{remaining_csv_file}'.\")\n",
    "\n",
    "# Example usage\n",
    "csv_file = '/home/studio-lab-user/sage/segregated_images/labels_pth.csv'\n",
    "num_to_remove = 25  # Number of records to remove\n",
    "removed_csv_file = '/home/studio-lab-user/sage/segregated_images/labels_test.csv'\n",
    "remaining_csv_file = '/home/studio-lab-user/sage/segregated_images/labels_train.csv'\n",
    "\n",
    "remove_and_verify_records(csv_file, num_to_remove, removed_csv_file, remaining_csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91130dfa-77aa-421e-b990-2b1b09668382",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:25<00:00,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed images saved to /home/studio-lab-user/sage/segregated_images/processed_images_test\n",
      "Updated CSV file saved to /home/studio-lab-user/sage/segregated_images/process_labels_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Define the paths\n",
    "original_csv_path = '/home/studio-lab-user/sage/segregated_images/labels_test.csv'  # Replace with your original CSV file path\n",
    "processed_images_folder = '/home/studio-lab-user/sage/segregated_images/processed_images_test'  # Folder to save processed images\n",
    "new_csv_path = '/home/studio-lab-user/sage/segregated_images/process_labels_test.csv'  # Path for the new CSV file\n",
    "\n",
    "# Create the folder for processed images if it does not exist\n",
    "os.makedirs(processed_images_folder, exist_ok=True)\n",
    "\n",
    "# Read the original CSV file\n",
    "df = pd.read_csv(original_csv_path)\n",
    "\n",
    "# Function to trim the image\n",
    "def trim(im):\n",
    "    percentage = 0.02\n",
    "    img = np.array(im)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    im_bin = img_gray > 0.1 * np.mean(img_gray[img_gray != 0])\n",
    "    row_sums = np.sum(im_bin, axis=1)\n",
    "    col_sums = np.sum(im_bin, axis=0)\n",
    "    rows = np.where(row_sums > img.shape[1] * percentage)[0]\n",
    "    cols = np.where(col_sums > img.shape[0] * percentage)[0]\n",
    "    min_row, min_col = np.min(rows), np.min(cols)\n",
    "    max_row, max_col = np.max(rows), np.max(cols)\n",
    "    im_crop = img[min_row : max_row + 1, min_col : max_col + 1]\n",
    "    return Image.fromarray(im_crop)\n",
    "\n",
    "# Function to resize the image while maintaining the aspect ratio\n",
    "def resize_maintain_aspect(image, desired_size):\n",
    "    old_size = image.size  # old_size[0] is in (width, height) format\n",
    "    ratio = float(desired_size) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "    im = image.resize(new_size, Image.LANCZOS)\n",
    "    new_im = Image.new(\"RGB\", (desired_size, desired_size))\n",
    "    new_im.paste(im, ((desired_size - new_size[0]) // 2, (desired_size - new_size[1]) // 2))\n",
    "    return new_im\n",
    "\n",
    "# Function to apply CLAHE to the entire color image\n",
    "def apply_clahe_color(image):\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "    limg = cv2.merge((cl, a, b))\n",
    "    final_image = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n",
    "    return final_image\n",
    "\n",
    "# Function to process each image\n",
    "def process_image(image_path, output_path, desired_size):\n",
    "    try:\n",
    "        # Load the image\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # Trim the image\n",
    "        trimmed_image = trim(image)\n",
    "        \n",
    "        # Resize the image while maintaining aspect ratio\n",
    "        resized_image = resize_maintain_aspect(trimmed_image, desired_size)\n",
    "        \n",
    "        # Convert the image back to a numpy array\n",
    "        resized_image_np = np.array(resized_image)\n",
    "        \n",
    "        # Apply CLAHE to the entire color image\n",
    "        final_image = apply_clahe_color(resized_image_np)\n",
    "        \n",
    "        # Save the processed image\n",
    "        final_image_pil = Image.fromarray(final_image)\n",
    "        final_image_pil.save(output_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "# Process each image and update the CSV file\n",
    "def process_images():\n",
    "    full_paths = []\n",
    "    desired_size = 1000  # Example size, you can adjust as needed\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        original_path = row['path']\n",
    "        image_name = os.path.basename(original_path)\n",
    "        processed_path = os.path.join(processed_images_folder, image_name)\n",
    "        \n",
    "        # Process the image\n",
    "        process_image(original_path, processed_path, desired_size)\n",
    "        \n",
    "        # Use the full path of the processed image\n",
    "        full_paths.append(os.path.abspath(processed_path))\n",
    "\n",
    "    # Add the new processed path to the dataframe\n",
    "    df['path'] = full_paths\n",
    "\n",
    "    # Save the updated DataFrame to a new CSV file\n",
    "    df.to_csv(new_csv_path, index=False)\n",
    "\n",
    "    print(f\"Processed images saved to {processed_images_folder}\")\n",
    "    print(f\"Updated CSV file saved to {new_csv_path}\")\n",
    "\n",
    "# Run the processing\n",
    "process_images()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2417e877-b32b-4a16-a02a-ca14ab9a6ff1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n",
      "Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0412b38e-1314-4b6c-8eb7-5e07cc772070",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    804\n",
      "0    802\n",
      "3    525\n",
      "4    400\n",
      "2    289\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = '/home/studio-lab-user/sage/segregated_images/process_labels_train.csv'\n",
    "retina_df = pd.read_csv(file_path)\n",
    "# Define reduction rates for specific classes\n",
    "class_reduction_rates = {\n",
    "    0: 0.20,  # Reduce class 0 by 50%\n",
    "    1: 0.62,  # Reduce class 1 by 50%\n",
    "    2: 0.41,\n",
    "    3: 0.52,  # Reduce class 2 by 50%\n",
    "}\n",
    "\n",
    "# Apply reduction for specified classes\n",
    "reduced_df = pd.DataFrame()\n",
    "for class_label, reduction_rate in class_reduction_rates.items():\n",
    "    class_df = retina_df[retina_df['label'] == class_label]\n",
    "    num_records = len(class_df)\n",
    "    reduced_num_records = int(num_records * reduction_rate)\n",
    "    \n",
    "    if reduced_num_records > 0:\n",
    "        class_df_reduced = class_df.sample(n=reduced_num_records, random_state=1)\n",
    "    else:\n",
    "        class_df_reduced = class_df\n",
    "    \n",
    "    reduced_df = pd.concat([reduced_df, class_df_reduced])\n",
    "\n",
    "# For classes that are not specified in the reduction rates, keep all records\n",
    "for class_label in retina_df['label'].unique():\n",
    "    if class_label not in class_reduction_rates:\n",
    "        class_df = retina_df[retina_df['label'] == class_label]\n",
    "        reduced_df = pd.concat([reduced_df, class_df])\n",
    "\n",
    "# Shuffle the updated DataFrame (optional, if you want to randomize the order)\n",
    "reduced_df = reduced_df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "level_counts = reduced_df['label'].value_counts()\n",
    "print(level_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88702c6e-e5c1-4719-8145-5252b265cb76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the reduced DataFrame to a new CSV file\n",
    "reduced_csv_file_path = 'processed_images_5_class_train.csv'\n",
    "reduced_df.to_csv(reduced_csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9209deb8-311a-4567-a8b5-83e3c99b73e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "2    793\n",
       "0    762\n",
       "1    739\n",
       "3    400\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('processed_images_4_class_train.csv')\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86105e43-bef2-4a65-a729-5f450fa3aa72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "2    814\n",
      "1    804\n",
      "0    802\n",
      "3    400\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "reduced_csv_file_path = 'processed_images_5_class_train.csv'\n",
    "# Define the function to map old labels to new groups\n",
    "def map_labels(level):\n",
    "    if level == 0:\n",
    "        return 0  # Group 0 for levels 0 and 1\n",
    "    if level == 1:\n",
    "        return 1\n",
    "    elif level in [2, 3]:\n",
    "        return 2  # Group 1 for levels 2 and 3\n",
    "    elif level == 4:\n",
    "        return 3  # Class 2 for level 4\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected level value\")\n",
    "\n",
    "# reduced_csv_file_path = 'total_data_class_mod.csv'\n",
    "df = pd.read_csv(reduced_csv_file_path)\n",
    "\n",
    "# Update 'level' column with new grouped labels\n",
    "df['label'] = df['label'].apply(map_labels)\n",
    "\n",
    "print(df['label'].value_counts())\n",
    "#803\t651\t (2: 284) + (3: 508) = 792\t\t405\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a19840d-2895-4a8f-9674-4f9fb3dff0da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the updated CSV file\n",
    "# updated_csv_file_path = 'total_data_class_mod.csv'\n",
    "df.to_csv('processed_images_4_class_train.csv', index=False)\n",
    "\n",
    "print(\"CSV file updated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6eefd1b-a74f-4499-ab00-9a4dca0abacd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    908\n",
       "2    838\n",
       "0    802\n",
       "3    400\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('processed_images_4_class_train.csv')\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96223ad-7673-4841-8d89-7a4e84389b35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemaker-distribution:Python",
   "language": "python",
   "name": "conda-env-sagemaker-distribution-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
