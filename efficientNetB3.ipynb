{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cd4616-7088-49bc-a5ed-297ad6d819dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "----------\n",
      "Train Loss: 1.5460 Acc: 0.4259\n",
      "Test Loss: 2.0485 Acc: 0.4242\n",
      "Best model saved as effinet_model_V12.pth\n",
      "Epoch 2/50\n",
      "----------\n",
      "Train Loss: 1.2760 Acc: 0.4911\n",
      "Test Loss: 7.2056 Acc: 0.4848\n",
      "Epoch 3/50\n",
      "----------\n",
      "Train Loss: 1.0905 Acc: 0.5418\n",
      "Test Loss: 1.6793 Acc: 0.5657\n",
      "Best model saved as effinet_model_V12.pth\n",
      "Epoch 4/50\n",
      "----------\n",
      "Train Loss: 0.8783 Acc: 0.5862\n",
      "Test Loss: 2.2310 Acc: 0.6263\n",
      "Epoch 5/50\n",
      "----------\n",
      "Train Loss: 0.8589 Acc: 0.5915\n",
      "Test Loss: 0.7931 Acc: 0.6061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved as effinet_model_V12.pth\n",
      "Epoch 6/50\n",
      "----------\n",
      "Train Loss: 0.7947 Acc: 0.6252\n",
      "Test Loss: 5.0876 Acc: 0.6465\n",
      "Epoch 7/50\n",
      "----------\n",
      "Train Loss: 0.7957 Acc: 0.6131\n",
      "Test Loss: 7.8667 Acc: 0.6364\n",
      "Epoch 8/50\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "import os #hai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = 1000\n",
    "BATCH_SIZE = 16\n",
    "NUM_CLASSES = 4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CHECKPOINT_PATH = 'checkpoint_effinet_V12.pth'\n",
    "BEST_MODEL_PATH = 'effinet_model_V12.pth'\n",
    "LOG_FILE = 'training_log_V12.txt'\n",
    "\n",
    "# Custom Dataset\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img = img.resize((IMG_SIZE, IMG_SIZE))\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            img = Image.new('RGB', (IMG_SIZE, IMG_SIZE))  # Create a blank image\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = transforms.ToTensor()(img)\n",
    "        return img, label\n",
    "\n",
    "# Model definition\n",
    "class EfficientNetB3Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(EfficientNetB3Model, self).__init__()\n",
    "        self.efficientnet = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.IMAGENET1K_V1)\n",
    "        # Freeze the base model\n",
    "        for param in self.efficientnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        # Unfreeze the last 100 layers\n",
    "        for param in list(self.efficientnet.parameters())[-100:]:\n",
    "            param.requires_grad = True\n",
    "        # Modify the classifier\n",
    "        num_ftrs = self.efficientnet.classifier[1].in_features\n",
    "        self.efficientnet.classifier = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.efficientnet(x)\n",
    "\n",
    "def log_epoch_details(epoch, train_loss, train_acc, test_loss, test_acc, test_report, is_best):\n",
    "    with open(LOG_FILE, 'a') as f:\n",
    "        f.write(f\"Epoch {epoch+1}\\n\")\n",
    "        f.write(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\\n\")\n",
    "        f.write(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\\n\")\n",
    "        f.write(\"Test Classification Report:\\n\")\n",
    "        f.write(test_report)\n",
    "        if is_best:\n",
    "            f.write(\"New best model saved!\\n\")\n",
    "        f.write(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "def get_classification_report(model, dataloader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    return classification_report(all_labels, all_preds)\n",
    "\n",
    "def save_best_model(model, epoch, accuracy):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'test_accuracy': accuracy\n",
    "    }, BEST_MODEL_PATH)\n",
    "    print(f\"Best model saved as {BEST_MODEL_PATH}\")\n",
    "\n",
    "\n",
    "# def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs, start_epoch=0):\n",
    "#     best_model_wts = None\n",
    "#     best_acc = 0.0\n",
    "#     for epoch in range(start_epoch, num_epochs):\n",
    "#         print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "#         print('-' * 10)\n",
    "#         # Training phase\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         for inputs, labels in train_loader:\n",
    "#             inputs = inputs.to(DEVICE)\n",
    "#             labels = labels.to(DEVICE)\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             running_loss += loss.item() * inputs.size(0)\n",
    "#             running_corrects += torch.sum(preds == labels.data)\n",
    "#         epoch_loss = running_loss / len(train_loader.dataset)\n",
    "#         epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "#         print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "#         # Testing phase\n",
    "#         model.eval()\n",
    "#         test_loss = 0.0\n",
    "#         test_corrects = 0\n",
    "#         with torch.no_grad():\n",
    "#             for inputs, labels in test_loader:\n",
    "#                 inputs = inputs.to(DEVICE)\n",
    "#                 labels = labels.to(DEVICE)\n",
    "#                 outputs = model(inputs)\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "#                 test_loss += loss.item() * inputs.size(0)\n",
    "#                 test_corrects += torch.sum(preds == labels.data)\n",
    "#         test_loss = test_loss / len(test_loader.dataset)\n",
    "#         test_acc = test_corrects.double() / len(test_loader.dataset)\n",
    "#         print(f'Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}')\n",
    "#         test_report = get_classification_report(model, test_loader)\n",
    "#         is_best = test_acc > best_acc\n",
    "#         if is_best:\n",
    "#             best_acc = test_acc\n",
    "#             best_model_wts = model.state_dict().copy()\n",
    "#             save_best_model(model, epoch, best_acc.item())\n",
    "#         scheduler.step(test_loss)\n",
    "#         log_epoch_details(epoch, epoch_loss, epoch_acc.item(), test_loss, test_acc.item(), test_report, is_best)\n",
    "#         # Save checkpoint\n",
    "#         save_checkpoint(epoch, model, optimizer, scheduler, best_acc.item())\n",
    "#     print(f'Best Test Acc: {best_acc:.4f}')\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "#     return model, best_acc.item()\n",
    "\n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs, start_epoch=0):\n",
    "    best_model_wts = None\n",
    "    best_loss = float('inf')  # Initialize best_loss to a high value\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "        print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "        \n",
    "        # Testing phase\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_corrects = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item() * inputs.size(0)\n",
    "                test_corrects += torch.sum(preds == labels.data)\n",
    "        test_loss = test_loss / len(test_loader.dataset)\n",
    "        test_acc = test_corrects.double() / len(test_loader.dataset)\n",
    "        print(f'Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}')\n",
    "        \n",
    "        test_report = get_classification_report(model, test_loader)\n",
    "        \n",
    "        # Check if the current model is the best based on validation loss\n",
    "        is_best = test_loss < best_loss\n",
    "        if is_best:\n",
    "            best_loss = test_loss  # Update best_loss\n",
    "            best_model_wts = model.state_dict().copy()\n",
    "            save_best_model(model, epoch, test_acc.item())  # You can also log test_loss if needed\n",
    "            \n",
    "        scheduler.step(test_loss)  # Optionally update the learning rate scheduler\n",
    "        log_epoch_details(epoch, epoch_loss, epoch_acc.item(), test_loss, test_acc.item(), test_report, is_best)\n",
    "        \n",
    "        # Save checkpoint\n",
    "        save_checkpoint(epoch, model, optimizer, scheduler, test_acc.item())\n",
    "        \n",
    "    print(f'Best Test Loss: {best_loss:.4f}')\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_loss\n",
    "\n",
    "def save_checkpoint(epoch, model, optimizer, scheduler, best_acc):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'best_acc': best_acc\n",
    "    }, CHECKPOINT_PATH)\n",
    "\n",
    "def load_checkpoint(model, optimizer, scheduler):\n",
    "    if os.path.exists(CHECKPOINT_PATH):\n",
    "        checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_acc = checkpoint['best_acc']\n",
    "        print(f\"Resuming from epoch {start_epoch} with best test accuracy: {best_acc:.4f}\")\n",
    "        return start_epoch, best_acc\n",
    "    return 0, 0.0\n",
    "\n",
    "\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the train CSV file\n",
    "    train_csv_file = 'processed_images_4_class_train.csv'\n",
    "    train_df = pd.read_csv(train_csv_file)\n",
    "\n",
    "    # Load the test CSV file\n",
    "    test_csv_file = 'processed_images_4_class_test.csv'\n",
    "    test_df = pd.read_csv(test_csv_file)\n",
    "\n",
    "    # Use 'level' column as the labels\n",
    "    train_labels = train_df['label'].values\n",
    "    test_labels = test_df['label'].values\n",
    "\n",
    "    # Use all train data for training\n",
    "    train_paths = train_df['path'].values\n",
    "\n",
    "    # Use all test data for testing\n",
    "    test_paths = test_df['path'].values\n",
    "\n",
    "    # Define transforms for training (no normalization)\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = ImageDataset(train_paths, train_labels, transform=train_transform)\n",
    "    test_dataset = ImageDataset(test_paths, test_labels, transform=None)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = EfficientNetB3Model(NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=5, min_lr=1e-7)\n",
    "\n",
    "    # Load checkpoint if exists\n",
    "    start_epoch, best_acc = load_checkpoint(model, optimizer, scheduler)\n",
    "\n",
    "    # Train the model\n",
    "    num_epochs = 50\n",
    "    model, best_acc = train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs, start_epoch)\n",
    "\n",
    "    # Load the best model for final evaluation\n",
    "    best_model_checkpoint = torch.load(BEST_MODEL_PATH)\n",
    "    model.load_state_dict(best_model_checkpoint['model_state_dict'])\n",
    "    # Evaluate the best model on test data\n",
    "    test_report = get_classification_report(model, test_loader)\n",
    "\n",
    "    # Append final test results to the log file\n",
    "    with open(LOG_FILE, 'a') as f:\n",
    "        f.write(\"\\nTraining Complete\\n\")\n",
    "        f.write(f\"Best Test Accuracy: {best_acc:.4f}\\n\")\n",
    "        f.write(\"Final Test Classification Report:\\n\")\n",
    "        f.write(test_report)\n",
    "\n",
    "    print(f\"Training complete. All details logged in {LOG_FILE}\")\n",
    "    print(f\"Best model saved as {BEST_MODEL_PATH} with test accuracy: {best_acc:.4f}\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30391155-244b-4de2-894d-fa1030d6cee0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3525"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('processed_images_4_class_train.csv')\n",
    "df['label'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52b18618-a3b8-4220-9d9a-b918dee749d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in the data: [0 1 2 3]\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           No DR       0.61      0.56      0.58        25\n",
      "            Mild       0.61      0.76      0.68        25\n",
      "          Severe       0.91      0.83      0.87        24\n",
      "Proliferative DR       1.00      0.92      0.96        25\n",
      "\n",
      "        accuracy                           0.77        99\n",
      "       macro avg       0.78      0.77      0.77        99\n",
      "    weighted avg       0.78      0.77      0.77        99\n",
      "\n",
      "Confusion matrix saved as 'confusion_matrix.png'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = 1000\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 4  # Corrected back to 4 classes\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BEST_MODEL_PATH = 'effinet_model.pth'\n",
    "\n",
    "# Custom Dataset\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img = img.resize((IMG_SIZE, IMG_SIZE))\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            img = Image.new('RGB', (IMG_SIZE, IMG_SIZE))  # Create a blank image\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = transforms.ToTensor()(img)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "# Model definition (unchanged)\n",
    "class EfficientNetB3Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(EfficientNetB3Model, self).__init__()\n",
    "        self.efficientnet = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # Modify the classifier\n",
    "        num_ftrs = self.efficientnet.classifier[1].in_features\n",
    "        self.efficientnet.classifier = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.efficientnet(x)\n",
    "\n",
    "\n",
    "def load_model(model_path):\n",
    "    model = EfficientNetB3Model(NUM_CLASSES).to(DEVICE)\n",
    "    checkpoint = torch.load(model_path, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    return model\n",
    "\n",
    "def predict(model, dataloader):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    return np.array(all_preds), np.array(all_labels)\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))  # Adjusted back for 4 classes\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.savefig('confusion_matrix_VO.png')\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the test CSV file\n",
    "    test_csv_file = 'processed_images_4_class_test.csv'\n",
    "    test_df = pd.read_csv(test_csv_file)\n",
    "\n",
    "    # Use 'level' column as the labels\n",
    "    test_labels = test_df['label'].values\n",
    "\n",
    "    # Use all test data for testing\n",
    "    test_paths = test_df['path'].values\n",
    "\n",
    "    # Create test dataset\n",
    "    test_dataset = ImageDataset(test_paths, test_labels, transform=None)\n",
    "\n",
    "    # Create test data loader\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Load the best model\n",
    "    model = load_model(BEST_MODEL_PATH)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions, true_labels = predict(model, test_loader)\n",
    "\n",
    "    # Check unique labels in the data\n",
    "    unique_labels = np.unique(true_labels)\n",
    "    print(\"Unique labels in the data:\", unique_labels)\n",
    "\n",
    "    # Generate classification report\n",
    "    class_names = ['No DR', 'Mild', 'Severe', 'Proliferative DR']  # Corrected back to 4 classes\n",
    "    report = classification_report(true_labels, predictions, target_names=class_names)\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    # Plot and save confusion matrix\n",
    "    plot_confusion_matrix(true_labels, predictions, class_names)\n",
    "    print(\"Confusion matrix saved as 'confusion_matrix.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90817099-081e-4612-a98b-737e94072dea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages (from seaborn) (2.1.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages (from seaborn) (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "! pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fe3716d-6d2f-4887-b651-f17f9d3ac8de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7677\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "179a473c-925d-4090-b967-9157fb34f23b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"left_eye\": {\n",
      "    \"predicted_class\": 3,\n",
      "    \"stage\": \"Left Eye\",\n",
      "    \"confidence\": \"92.05%\",\n",
      "    \"explanation\": \"Proliferative Diabetic Retinopathy (PDR): Neovascularization: Growth of new, abnormal blood vessels on the retina. Cotton Wool Spots: Soft lesions caused by localized retinal ischemia. This stage carries a significant risk of vision loss and complications, necessitating urgent medical intervention.\",\n",
      "    \"Note\": \"Proliferative diabetic retinopathy detected. Urgent medical intervention is necessary to prevent severe vision loss. Please consult your healthcare provider immediately.\",\n",
      "    \"Risk\": \"92.05%\"\n",
      "  },\n",
      "  \"right_eye\": {\n",
      "    \"predicted_class\": 3,\n",
      "    \"stage\": \"Right Eye\",\n",
      "    \"confidence\": \"92.05%\",\n",
      "    \"explanation\": \"Proliferative Diabetic Retinopathy (PDR): Neovascularization: Growth of new, abnormal blood vessels on the retina. Cotton Wool Spots: Soft lesions caused by localized retinal ischemia. This stage carries a significant risk of vision loss and complications, necessitating urgent medical intervention.\",\n",
      "    \"Note\": \"Proliferative diabetic retinopathy detected. Urgent medical intervention is necessary to prevent severe vision loss. Please consult your healthcare provider immediately.\",\n",
      "    \"Risk\": \"92.05%\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "CATEGORY_MAPPING = {\n",
    "    0: 'No Diabetic Retinopathy',\n",
    "    1: 'Mild Diabetic Retinopathy',\n",
    "    2: 'Moderate to Severe Diabetic Retinopathy',\n",
    "    3: 'Proliferative Diabetic Retinopathy'\n",
    "}\n",
    "\n",
    "explanation_labels = {\n",
    "    0: (\n",
    "        'No DR: No diabetic retinopathy detected. '\n",
    "        'There is a low chance of developing diabetic retinopathy if blood sugar levels are well-managed.'\n",
    "    ),\n",
    "    1: (\n",
    "        'Mild NPDR (Nonproliferative Diabetic Retinopathy): '\n",
    "        'Microaneurysms: Small, localized dilations of blood vessels in the retina. '\n",
    "        'This stage may indicate a moderate chance of progression if not monitored and managed properly.'\n",
    "    ),\n",
    "    2: (\n",
    "        'Moderate to Severe NPDR: '\n",
    "        'Hemorrhages: Includes both dot-and-blot and flame-shaped hemorrhages. '\n",
    "        'Exudates: Prominent soft and hard exudates may be present, along with retinal edema. '\n",
    "        'This stage represents a high chance of further progression if left untreated, requiring close monitoring and intervention.'\n",
    "    ),\n",
    "    3: (\n",
    "        'Proliferative Diabetic Retinopathy (PDR): '\n",
    "        'Neovascularization: Growth of new, abnormal blood vessels on the retina. '\n",
    "        'Cotton Wool Spots: Soft lesions caused by localized retinal ischemia. '\n",
    "        'This stage carries a significant risk of vision loss and complications, necessitating urgent medical intervention.'\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "# Model definition (same as before)\n",
    "class EfficientNetB3Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(EfficientNetB3Model, self).__init__()\n",
    "        self.efficientnet = models.efficientnet_b3(weights=None)\n",
    "        num_ftrs = self.efficientnet.classifier[1].in_features\n",
    "        self.efficientnet.classifier = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.efficientnet(x)\n",
    "\n",
    "# Image processing functions (same as before)\n",
    "def trim(im):\n",
    "    percentage = 0.02\n",
    "    img = np.array(im)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    im_bin = img_gray > 0.1 * np.mean(img_gray[img_gray != 0])\n",
    "    row_sums = np.sum(im_bin, axis=1)\n",
    "    col_sums = np.sum(im_bin, axis=0)\n",
    "    rows = np.where(row_sums > img.shape[1] * percentage)[0]\n",
    "    cols = np.where(col_sums > img.shape[0] * percentage)[0]\n",
    "    min_row, min_col = np.min(rows), np.min(cols)\n",
    "    max_row, max_col = np.max(rows), np.max(cols)\n",
    "    im_crop = img[min_row : max_row + 1, min_col : max_col + 1]\n",
    "    return Image.fromarray(im_crop)\n",
    "\n",
    "def resize_maintain_aspect(image, desired_size):\n",
    "    old_size = image.size\n",
    "    ratio = float(desired_size) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "    im = image.resize(new_size, Image.LANCZOS)\n",
    "    new_im = Image.new(\"RGB\", (desired_size, desired_size))\n",
    "    new_im.paste(im, ((desired_size - new_size[0]) // 2, (desired_size - new_size[1]) // 2))\n",
    "    return new_im\n",
    "\n",
    "def apply_clahe_color(image):\n",
    "    lab = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "    limg = cv2.merge((cl, a, b))\n",
    "    final_image = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n",
    "    return Image.fromarray(final_image)\n",
    "\n",
    "def process_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    trimmed_image = trim(image)\n",
    "    resized_image = resize_maintain_aspect(trimmed_image, IMG_SIZE)\n",
    "    final_image = apply_clahe_color(resized_image)\n",
    "    return final_image\n",
    "\n",
    "\n",
    "# New function to generate detailed results\n",
    "def generate_result(predicted_class, confidence, stage):\n",
    "    explanation = explanation_labels.get(predicted_class, 'Unknown')\n",
    "    confidence_percentage = round(confidence * 100, 2)\n",
    "    \n",
    "    if predicted_class == 3:  # Proliferative Diabetic Retinopathy\n",
    "        Risk_Factor = round(confidence * 100, 2)\n",
    "    else:\n",
    "        Risk_Factor = round((1 - confidence) * 100, 2)\n",
    "    \n",
    "    result = {\n",
    "        \"predicted_class\": int(predicted_class),\n",
    "        \"confidence\": confidence_percentage,\n",
    "        \"explanation\": explanation,\n",
    "        \"warning\": None,\n",
    "        \"Risk_Factor\": Risk_Factor,\n",
    "        \"Stage\": stage\n",
    "    }\n",
    "    \n",
    "    if confidence < 0.55 and predicted_class == 0:\n",
    "        result[\"warning\"] = f\"You have a higher chance of progressing to the next stage with a risk factor of {Risk_Factor}%. Please consult your doctor for further advice.\"\n",
    "    elif confidence >= 0.55 and confidence <= 0.74 and predicted_class == 0:\n",
    "        result[\"warning\"] = f\"You have a minimum chance of progressing to the next stage with a risk factor of {Risk_Factor}%.\"\n",
    "    elif confidence >= 0.75 and predicted_class == 0:\n",
    "        result[\"warning\"] = \"Your eye is in the safe zone.\"\n",
    "    elif predicted_class == 1:  # Mild Diabetic Retinopathy\n",
    "        result[\"warning\"] = f\"Mild diabetic retinopathy detected. Risk factor is {Risk_Factor}%. Please consult your doctor for further advice.\"\n",
    "    elif predicted_class == 2:  # Moderate to Severe Diabetic Retinopathy\n",
    "        result[\"warning\"] = f\"Moderate to severe diabetic retinopathy detected. Risk factor is {Risk_Factor}%. Please consult your doctor for further advice.\"\n",
    "    elif predicted_class == 3:  # Proliferative Diabetic Retinopathy\n",
    "        result[\"warning\"] = \"Proliferative diabetic retinopathy detected. Urgent medical intervention is necessary to prevent severe vision loss. Please consult your healthcare provider immediately.\"\n",
    "    \n",
    "    return {\n",
    "        \"predicted_class\": result[\"predicted_class\"],\n",
    "        \"stage\": result[\"Stage\"],\n",
    "        \"confidence\": f\"{result['confidence']}%\",\n",
    "        \"explanation\": result[\"explanation\"],\n",
    "        \"Note\": result[\"warning\"],\n",
    "        \"Risk\": f\"{result['Risk_Factor']}%\",\n",
    "    }\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = 600\n",
    "NUM_CLASSES = 4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BEST_MODEL_PATH = 'effinet_model_1.pth'\n",
    "\n",
    "\n",
    "def infer(model, image_path, transform):\n",
    "    img = process_image(image_path)\n",
    "    img_tensor = transform(img).unsqueeze(0).to(DEVICE)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        confidence, predicted = torch.max(probabilities, 1)\n",
    "    \n",
    "    return predicted.item(), confidence.item()\n",
    "\n",
    "# Main inference function (updated)\n",
    "def run_inference(left_image_path, right_image_path):\n",
    "    # Load the model\n",
    "    model = EfficientNetB3Model(NUM_CLASSES).to(DEVICE)\n",
    "    checkpoint = torch.load(BEST_MODEL_PATH, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Define transform\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    # Run inference on both images\n",
    "    left_class, left_confidence = infer(model, left_image_path, transform)\n",
    "    right_class, right_confidence = infer(model, right_image_path, transform)\n",
    "    \n",
    "    # Generate detailed results\n",
    "    left_result = generate_result(left_class, left_confidence, \"Left Eye\")\n",
    "    right_result = generate_result(right_class, right_confidence, \"Right Eye\")\n",
    "    \n",
    "    # Prepare final results\n",
    "    results = {\n",
    "        \"left_eye\": left_result,\n",
    "        \"right_eye\": right_result\n",
    "    }\n",
    "    \n",
    "    return json.dumps(results, indent=2)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    left_image_path = \"/home/studio-lab-user/sage/segregated_images/4/1138_right.jpeg\"\n",
    "    right_image_path = \"/home/studio-lab-user/sage/segregated_images/4/1138_right.jpeg\"\n",
    "    \n",
    "    results = run_inference(left_image_path, right_image_path)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24afff7f-10f7-4323-9388-55773a323912",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemaker-distribution:Python",
   "language": "python",
   "name": "conda-env-sagemaker-distribution-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
